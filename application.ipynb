{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa4a6d1",
   "metadata": {},
   "source": [
    "# Implémentation un moteur d’inférence API . \n",
    "L'objectif de l’API est de renvoyer le sentiment à réception d’un texte brut 'API ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667f86fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import flask\n",
    "from flask import Flask, jsonify, request\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fabf459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of            target                                               text   \n",
      "0        NEGATIVE  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \\\n",
      "1        NEGATIVE  is upset that he can't update his Facebook by ...   \n",
      "2        NEGATIVE  @Kenichan I dived many times for the ball. Man...   \n",
      "3        NEGATIVE    my whole body feels itchy and like its on fire    \n",
      "4        NEGATIVE  @nationwideclass no, it's not behaving at all....   \n",
      "...           ...                                                ...   \n",
      "1597484  POSITIVE  Just woke up. Having no school is the best fee...   \n",
      "1597485  POSITIVE  TheWDB.com - Very cool to hear old Walt interv...   \n",
      "1597486  POSITIVE  Are you ready for your MoJo Makeover? Ask me f...   \n",
      "1597487  POSITIVE  Happy 38th Birthday to my boo of alll time!!! ...   \n",
      "1597488  POSITIVE  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
      "\n",
      "                                                clean_text  \n",
      "0        switchfoot httptwitpiccom awww s bummer should...  \n",
      "1        upset not update facebook texte cry result sch...  \n",
      "2           kenichan dive time ball manage save rest bound  \n",
      "3                                body feel itchy like fire  \n",
      "4                         nationwideclass behave m mad not  \n",
      "...                                                    ...  \n",
      "1597484                      wake have school good feeling  \n",
      "1597485  thewdbcom cool hear old walt interview httpblipfm  \n",
      "1597486                     ready mojo makeover ask detail  \n",
      "1597487    happy birthday boo alll time tupac amaru shakur  \n",
      "1597488        happy charitytuesday thenspcc sparkscharity  \n",
      "\n",
      "[1597489 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "# initialize our Flask application and the Keras model\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('input_app/df_cleaned_docs.csv',encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f5155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doly9\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\preprocessing\\text.py:246: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenizer\n",
    "tokenizer = Tokenizer(nb_words=14225)\n",
    "tokenizer.fit_on_texts( df['clean_text'])\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(\"input_app/word2vec_lstm_epoch_30.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b35f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters\n",
    "def remove_special_characters(text):\n",
    "    #Removing numerical values, Removing Digits and words containing digits\n",
    "    text= re.sub('\\w*\\d\\w*','', text)\n",
    "    #Removing punctations\n",
    "    text= re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    #Removing Extra Spaces\n",
    "    text =re.sub(' +', ' ',text)\n",
    "    # remove stock market tickers like $GE\n",
    "    text = re.sub(r'\\$\\w*', '',text)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    text = re.sub(r'^RT[\\s]+', '',text)\n",
    "    # remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '',text)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    text = re.sub(r'#', '',text)\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "def tokenize_stopwords_lemmatize(texts, allowed_postags=['NOUN','ADJ','ADV']):\n",
    "    tokenized_docs = texts.apply(lambda x: ' '.join([token.lemma_.lower() for token in list(nlp(x)) if token.is_alpha and not token.is_stop]))\n",
    "    return tokenized_docs\n",
    "\n",
    "def encode_text(text):\n",
    "    #tokenizer = Tokenizer(nb_words=14225)\n",
    "    #tokenizer.fit_on_texts([text])\n",
    "    #sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_test_sequence = pad_sequences(sequence, maxlen=30)\n",
    "    print(padded_test_sequence)\n",
    "    return padded_test_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906eb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/', methods=['GET'])\n",
    "def ping():\n",
    "    return 'Hello, World!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict', methods=['POST'])\n",
    "\n",
    "def predict():\n",
    "    #global model\n",
    "    data = request.get_json(force=True)\n",
    "    text = data['text']\n",
    "    #print(text)\n",
    "    cleaned_text = remove_special_characters(text)\n",
    "    encoded_text = encode_text(cleaned_text)\n",
    "    predict_output = model.predict(encoded_text)[0][0]\n",
    "    \n",
    "    if predict_output>0.5:\n",
    "        output = {'result of model': \"The sentiment of this text is positive, with a polarity score of {0:.2f}\".format(predict_output)}\n",
    "    else:\n",
    "        output = {'result of model': \"The sentiment of this text is negative, with a polarity score of {0:.2f}\".format(predict_output)}\n",
    "\n",
    "    \n",
    "    return jsonify(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16f3a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    #load_model()\n",
    "    app.run(debug=True,use_reloader=False, port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42523859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b89aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552135b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envproject7_tf12",
   "language": "python",
   "name": "envproject7_tf12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
